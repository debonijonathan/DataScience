{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Istruzioni\n",
    "Valgono le stesse istruzioni delle esercitazioni precedenti. \n",
    "\n",
    "Scrivi il programma Python nella cella sotto il testo dell'esercizio (o creane una nuova). Stampa sempre a video il risultato finale per verificare la correttezza dell'esercizio.  Talvolta richiamiamo alcuni concetti importanti in una cella di codice sotto il testo dell'esercizio, prova a eseguirla ed eventualmente modificarla per assicurarti di aver capito il necessario.\n",
    "\n",
    "**Nota.** Alcuni esercizi potrebbero richiedere una semplice risposta a delle domande. In questo caso potete scrivere la soluzione in una cella di tipo \"Markdown\".  \n",
    "\n",
    "\n",
    "## Consegna\n",
    "Valgono le regole delle esercitazioni precedenti.\n",
    "\n",
    "E' obbligatorio **consegnare la soluzione di tutti gli esercizi** (tranne quelli marcati come opzionali) **entro l'inizio della lezione successiva** (in questo caso entro Lunedi' prossimo), nell'apposito assignment su iCorsi.  Per consegnare:\n",
    "- eseguire l'intero notebook partendo da zero (`Kernel -> Restart & Run All`), e controllare che le soluzioni siano quelle attese;\n",
    "- esportare il notebook in formato html (`File -> Download as...`) e consegnare il file risultante.\n",
    "\n",
    "Nel caso non abbiate potuto completare uno o piu' esercizi, descrivete il problema incontrato e **consegnate comunque il file con il resto delle soluzioni**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 1 \n",
    "\n",
    "Si consideri il dataset visto a lezione e nell'esercitazione precedente sulla classificazione delle cellule tumorali.\n",
    "\n",
    "Quando si lavora con dati provenienti da esami clinici, in genere si dice che un'istanza è di classe positiva (+1) se il test clinico è positivo (es., presenza di tumore maligno), mentre l'istanza è di classe negativa (-1) se il test è negativo (es., il tumore NON è maligno). \n",
    "\n",
    "Il dataset utilizzato non usa questa convenzione. Eseguite la cella sotto per caricare il dataset e convertire la variabile target secondo la convezione descritta sopra (y = 1: tumore maligno; y = -1: tumore benigno). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "ds = sklearn.datasets.load_breast_cancer()\n",
    "\n",
    "x = ds.data\n",
    "yT = ds.target # Il datset originale usa la convezione yT = 0 per tumore maligno, yT = 1 per tumore benigno \n",
    "y = yT\n",
    "\n",
    "# Convertiamo la label secondo la convenzione: y = 1 per tumore maligno, y = -1 per tumore benigno\n",
    "y[yT == 1] = -1\n",
    "y[yT == 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "Dopo aver diviso in **maniera casuale** il dataset completo in set di training (70% delle osservazioni) e set di test (rimanente 30% percento), normalizzate ogni attributo come visto a lezione, in modo che le osservazioni di ogni attributo del training set abbiano media nulla e deviazione standard unitaria. Utilizzando media e deviazione standard **utilizzate per normalizzare gli attributi del training set**, riscalate anche le osservazioni del test set.\n",
    "\n",
    "- Calcolate media e deviazione standard di ogni attributo per le osservazioni del training set. Verificate che siano uguali a 0 e a 1, rispettivamente.\n",
    "\n",
    "- Calcolate media e deviazione standard di ogni attributo per le osservazioni del test set. Sono rispettivamente uguali a 0 e a 1? Perchè? \n",
    "\n",
    "Da ora in avanti, si considerino sempre gli attributi normalizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig set: \n",
      " Media: 62.10876596785595, \n",
      " Std: 229.3446999711776\n",
      "\n",
      "Normalized training set: \n",
      " Media: [-1.20869255e-15 -3.93292322e-15 -3.50361839e-15  2.23160407e-16\n",
      " -2.97863353e-15  9.79674187e-16  5.20521649e-16  2.25949912e-16\n",
      " -1.35005072e-15  3.02103401e-16  5.08247827e-16 -3.65425166e-16\n",
      " -1.17996065e-16 -6.12575317e-16 -1.19056077e-15 -2.49270175e-15\n",
      " -3.00429698e-16  1.11663889e-15 -3.51756591e-16 -1.23017174e-16\n",
      "  6.05880505e-16  3.82162197e-16 -1.60396543e-15 -1.79644128e-15\n",
      " -2.81461063e-16 -1.61233394e-16 -4.34604893e-16  7.29455580e-16\n",
      "  1.52753299e-15 -3.03609734e-15], \n",
      " Std: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Normalized test set: \n",
      " Media: [-2.22986022e-15  1.46471529e-15 -6.09648784e-16 -1.86011051e-16\n",
      "  9.03760497e-16  6.94700957e-17 -2.75283370e-16 -1.03068950e-16\n",
      "  4.95380215e-16  4.56733417e-15  4.00589243e-16 -4.49283236e-16\n",
      "  2.91190074e-16  2.66843078e-16 -8.79088874e-16 -3.19432590e-16\n",
      " -3.27223628e-16 -2.61973679e-16 -2.59701292e-16  9.93357443e-16\n",
      " -6.31074140e-16  6.90805438e-16  6.70840901e-16  2.02242381e-16\n",
      " -1.54944284e-15  1.23358114e-16  5.99909985e-16 -4.17469827e-16\n",
      "  5.08365280e-16  1.72181957e-15], \n",
      " Std: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution (to be completed)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.3, random_state=42) # 30% nei test e il numero di volte che deve essere mescolato\n",
    "\n",
    "m,n = np.shape(xTrain) # Compute number of observations in training set and maximum number of features\n",
    "\n",
    "# Compute mean and std in training observations\n",
    "xMean = np.mean(xTrain)\n",
    "xStd = np.std(xTrain)\n",
    "\n",
    "print(f\"Trainig set: \\n Media: {xMean}, \\n Std: {xStd}\\n\")\n",
    "\n",
    "# Scale training data\n",
    "xTrainScaled = preprocessing.scale(xTrain)\n",
    "print(f\"Normalized training set: \\n Media: {np.mean(xTrainScaled, axis = 0)}, \\n Std: {np.std(xTrainScaled, axis = 0)}\\n\")\n",
    "\n",
    "# Scale test data\n",
    "xTestScaled = preprocessing.scale(xTest)\n",
    "print(f\"Normalized test set: \\n Media: {np.mean(xTestScaled, axis = 0)}, \\n Std: {np.std(xTestScaled, axis = 0)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "In tutto abbimo 30 attributi. Si considerino i primi due, che corrispondono ai seguenti attributi ['radius_mean', 'texture_mean']. \n",
    "\n",
    "Si generi lo scatterplot per le 2 features con le osservazioni del dataset di training. Disegnate con puntini rossi le osservazioni in cui la variabile target y è uguale a 1 (tumore maligno) e con punti blu le osservazioni in cui la variabile target y è uguale a -1 (tumore benigno).\n",
    "\n",
    "Guardando lo scatterplot appena generato, dite se le seguenti affermazioni sono vere o false\n",
    "- Sia data una variabile di test con 'radius_mean' = 3 e 'texture_mean'= 1. Un algoritmo di classificazione k-NN, con `k=11`, associa la variabile di test alla classe positiva.\n",
    "- Sia data una variabile di test con 'radius_mean' = -1 e 'texture_mean'= 2. Un algoritmo di classificazione k-NN, con `k=11`, associa la variabile di test alla classe positiva.\n",
    "-  Sia data una variabile di test con 'radius_mean' = 1 e 'texture_mean'= -1.1. Un algoritmo di classificazione k-NN, con `k=1`, associa la variabile di test alla classe positiva \n",
    "-  Sia data una variabile di test con 'radius_mean' = 1 e 'texture_mean'= -1.1. Un algoritmo di classificazione k-NN, con `k=5`, associa la variabile di test alla classe positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgba(0, 0, 255, .8)",
          "size": 10
         },
         "mode": "markers",
         "name": "tumore beigno",
         "type": "scatter",
         "uid": "b4f9eb38-f564-11e8-bf90-309c2316f643",
         "x": [
          13.74,
          13.37,
          14.69,
          12.91,
          13.62,
          15,
          11.8,
          14.53,
          13.71,
          11.36,
          8.726,
          14.47,
          13.54,
          12.85,
          12.47,
          12.46,
          10.86,
          11.37,
          13.49,
          9.567,
          11.06,
          14.61,
          7.691,
          13.69,
          11.46,
          12.06,
          13.15,
          10.26,
          9.333,
          11.06,
          10.66,
          10.51,
          12.67,
          11.08,
          11.04,
          12.43,
          14.87,
          12.87,
          9.465,
          13.16,
          10.91,
          12.25,
          12.75,
          14.58,
          12.27,
          12.16,
          12.99,
          13.27,
          13.87,
          13.87,
          13.59,
          8.95,
          13.65,
          11.47,
          14.42,
          12.05,
          9.683,
          10.97,
          12.54,
          14.34,
          11.76,
          13.03,
          16.84,
          13.21,
          8.671,
          11.87,
          12.76,
          12.65,
          11.31,
          11.94,
          14.96,
          11.6,
          9.731,
          11.27,
          14.02,
          10.51,
          9.876,
          11.57,
          12.31,
          13.66,
          10.32,
          12.21,
          12.21,
          12.87,
          12.18,
          16.5,
          12.04,
          10.05,
          11.28,
          8.618,
          12.63,
          12.54,
          13,
          10.6,
          11.62,
          11.89,
          9,
          9.042,
          13.9,
          14.95,
          13.46,
          14.5,
          12.18,
          12.9,
          9.787,
          12.2,
          11.85,
          11.41,
          13.2,
          16.17,
          12.45,
          11.95,
          13.85,
          15.19,
          11.06,
          11.14,
          12.94,
          13.24,
          13.05,
          13.85,
          13.3,
          12.72,
          12,
          14.26,
          12.81,
          9.405,
          10.94,
          8.597,
          8.219,
          10.57,
          13.2,
          12.39,
          11.71,
          14.04,
          11.22,
          11.93,
          11.41,
          12.72,
          10.57,
          13.27,
          9.397,
          14.76,
          11.51,
          12.58,
          9.847,
          9.676,
          12.36,
          11.63,
          15.71,
          14.8,
          14.97,
          11.3,
          14.92,
          10.9,
          12.32,
          11.43,
          11.68,
          11.16,
          14.53,
          13.56,
          11.34,
          13.64,
          13.64,
          14.59,
          9.668,
          13.01,
          8.571,
          9.876,
          8.878,
          12.8,
          12.22,
          10.96,
          10.44,
          12.88,
          9.436,
          11.6,
          12.95,
          8.598,
          16.14,
          13.59,
          12.03,
          12.23,
          11.49,
          13.66,
          11.26,
          12.7,
          8.734,
          15.1,
          12.77,
          14.11,
          11.71,
          11.71,
          12.46,
          11.89,
          12.27,
          13.85,
          11.94,
          11.26,
          13.77,
          11.69,
          11.5,
          14.05,
          13.38,
          10.49,
          11.66,
          10.71,
          13.7,
          11.99,
          10.2,
          11.93,
          14.2,
          13.05,
          12.07,
          11.45,
          16.3,
          10.8,
          12.62,
          10.26,
          12.42,
          12.49,
          13.88,
          9.742,
          10.8,
          15.73,
          12.88,
          9.268,
          13.75,
          12.3,
          12.83,
          11.74,
          13.05,
          10.88,
          9.504,
          11.54,
          9.755,
          11.75,
          11.33,
          12.77,
          14.99,
          17.85,
          13.5,
          12.19,
          13,
          13.14,
          13.08,
          8.888,
          11.64,
          14.29,
          12.18
         ],
         "y": [
          17.91,
          16.39,
          13.98,
          16.33,
          23.23,
          15.51,
          17.26,
          13.98,
          18.68,
          17.57,
          15.83,
          24.99,
          14.36,
          21.37,
          17.31,
          19.89,
          21.48,
          18.89,
          22.3,
          15.91,
          14.83,
          15.69,
          25.44,
          16.07,
          18.16,
          18.9,
          15.34,
          16.58,
          21.94,
          17.12,
          15.15,
          20.19,
          17.3,
          14.71,
          14.93,
          17,
          20.21,
          16.21,
          21.01,
          20.54,
          12.35,
          22.44,
          16.7,
          13.66,
          29.97,
          18.03,
          14.23,
          14.76,
          20.7,
          16.21,
          17.84,
          15.76,
          13.16,
          16.03,
          16.54,
          14.63,
          19.34,
          17.2,
          16.32,
          13.47,
          21.6,
          18.42,
          19.46,
          28.06,
          14.45,
          21.54,
          13.37,
          18.17,
          19.04,
          20.76,
          19.1,
          18.36,
          15.34,
          15.5,
          15.66,
          23.09,
          19.4,
          19.04,
          16.52,
          19.13,
          16.35,
          14.09,
          18.02,
          19.54,
          14.08,
          18.29,
          28.14,
          17.53,
          13.39,
          11.79,
          20.76,
          18.07,
          20.78,
          18.95,
          18.18,
          21.17,
          14.4,
          18.9,
          19.24,
          18.77,
          28.21,
          10.89,
          17.84,
          15.92,
          19.94,
          15.21,
          17.46,
          14.92,
          17.43,
          16.07,
          16.41,
          14.96,
          17.21,
          13.21,
          14.96,
          14.07,
          16.17,
          20.13,
          18.59,
          19.6,
          21.57,
          13.78,
          28.23,
          19.65,
          13.06,
          21.7,
          18.59,
          18.6,
          20.7,
          18.32,
          15.82,
          17.48,
          16.67,
          15.98,
          33.81,
          21.53,
          10.82,
          17.67,
          20.22,
          17.02,
          21.68,
          14.74,
          23.93,
          18.4,
          15.68,
          13.14,
          18.54,
          29.29,
          13.93,
          17.66,
          16.95,
          18.19,
          14.93,
          12.96,
          12.39,
          17.31,
          16.17,
          21.41,
          19.34,
          13.9,
          18.61,
          16.34,
          15.6,
          22.68,
          18.1,
          22.22,
          13.1,
          17.27,
          15.49,
          17.46,
          20.04,
          17.62,
          15.46,
          18.22,
          18.32,
          12.84,
          16.02,
          20.98,
          14.86,
          21.84,
          17.93,
          19.56,
          14.59,
          15.15,
          19.96,
          12.17,
          16.84,
          16.39,
          29.43,
          12.88,
          15.45,
          17.19,
          12.83,
          18.35,
          17.92,
          15.18,
          18.24,
          19.83,
          13.27,
          24.44,
          18.45,
          27.15,
          30.72,
          18.61,
          17.07,
          20.39,
          17.64,
          24.89,
          17.48,
          10.91,
          20.53,
          13.84,
          13.44,
          20.97,
          15.7,
          21.98,
          17.15,
          14.71,
          15.04,
          16.85,
          16.16,
          15.67,
          9.71,
          11.28,
          28.92,
          12.87,
          23.77,
          15.9,
          15.73,
          14.69,
          19.31,
          15.62,
          12.44,
          10.72,
          28.2,
          20.18,
          14.16,
          21.41,
          22.11,
          13.23,
          12.71,
          13.29,
          25.13,
          20.74,
          15.71,
          14.64,
          18.33,
          16.82,
          20.52
         ]
        },
        {
         "marker": {
          "color": "rgba(255, 0, 0, .8)",
          "size": 10
         },
         "mode": "markers",
         "name": "tumore maligno",
         "type": "scatter",
         "uid": "b4f9fe9e-f564-11e8-83a9-309c2316f643",
         "x": [
          17.35,
          16.11,
          18.49,
          13.71,
          15.46,
          19.21,
          18.81,
          17.14,
          19.07,
          19.16,
          19.8,
          13.61,
          11.84,
          14.71,
          16.65,
          16.13,
          21.75,
          14.27,
          15.06,
          27.22,
          21.16,
          20.16,
          12.45,
          18.65,
          15.61,
          14.68,
          11.42,
          17.06,
          14.58,
          12.83,
          20.48,
          14.86,
          17.47,
          12.34,
          20.09,
          17.95,
          16.69,
          16.35,
          14.25,
          17.3,
          20.59,
          16.27,
          17.29,
          18.03,
          11.76,
          14.99,
          19.18,
          11.8,
          25.73,
          24.63,
          17.46,
          19.44,
          20.47,
          20.18,
          24.25,
          23.29,
          20.34,
          20.44,
          18.82,
          21.71,
          15.75,
          18.22,
          19.53,
          19.79,
          15.05,
          19.59,
          20.64,
          17.08,
          20.51,
          23.27,
          18.22,
          18.08,
          15.66,
          18.01,
          19,
          17.91,
          13.17,
          14.78,
          16.24,
          18.46,
          18.31,
          19.17,
          16.74,
          15.3,
          20.26,
          15.75,
          16.25,
          10.95,
          15.46,
          15.49,
          19.4,
          19.45,
          20.29,
          19.55,
          14.9,
          13.61,
          17.42,
          13.43,
          13.86,
          13.17,
          17.02,
          15.5,
          18.45,
          18.61,
          17.05,
          20.31,
          19.59,
          18.31,
          14.95,
          14.25,
          12.77,
          13,
          12.68,
          19.53,
          13.73,
          17.68,
          13.44,
          11.08,
          18.77,
          23.21,
          17.01,
          28.11,
          27.42,
          16.6,
          17.54,
          19.19,
          13.28,
          14.22,
          15.53,
          13.11,
          19.55,
          20.57,
          15.12,
          16.13,
          20.2,
          15.37,
          23.51,
          15.85,
          20.92,
          19.73,
          14.6,
          19.68,
          14.42,
          21.37,
          19.02,
          16.03,
          14.19,
          18.66,
          13.98
         ],
         "y": [
          23.06,
          18.05,
          17.52,
          20.83,
          11.89,
          18.57,
          19.98,
          16.4,
          24.81,
          26.6,
          21.56,
          24.69,
          18.7,
          21.59,
          21.38,
          20.68,
          20.99,
          22.55,
          19.83,
          21.87,
          23.04,
          19.66,
          15.7,
          17.6,
          19.38,
          20.13,
          20.38,
          21,
          21.53,
          22.33,
          21.46,
          23.21,
          24.68,
          26.86,
          23.86,
          20.01,
          20.2,
          23.29,
          21.72,
          17.08,
          21.24,
          20.71,
          22.13,
          16.85,
          18.14,
          25.2,
          22.49,
          16.58,
          17.46,
          21.6,
          39.28,
          18.82,
          20.67,
          19.54,
          20.2,
          26.67,
          21.51,
          21.78,
          21.97,
          17.25,
          20.25,
          18.7,
          32.47,
          25.12,
          19.07,
          25,
          17.35,
          27.15,
          27.81,
          22.04,
          18.87,
          21.84,
          23.2,
          20.56,
          18.91,
          21.02,
          21.81,
          23.94,
          18.77,
          18.52,
          18.58,
          24.8,
          21.59,
          25.27,
          23.03,
          19.22,
          19.51,
          21.35,
          23.95,
          19.97,
          18.18,
          19.33,
          14.34,
          28.77,
          22.53,
          24.98,
          25.56,
          19.63,
          16.93,
          18.66,
          23.98,
          21.08,
          21.91,
          20.25,
          19.08,
          27.06,
          18.15,
          20.58,
          17.57,
          22.15,
          22.47,
          21.82,
          23.84,
          18.9,
          22.61,
          20.74,
          21.58,
          18.83,
          21.43,
          26.97,
          20.26,
          18.47,
          26.27,
          28.08,
          19.32,
          15.94,
          20.28,
          23.12,
          33.56,
          15.56,
          23.21,
          17.77,
          16.68,
          17.88,
          26.83,
          22.76,
          24.27,
          23.95,
          25.09,
          19.82,
          23.29,
          21.68,
          19.77,
          15.1,
          24.59,
          15.51,
          23.81,
          17.12,
          19.62
         ]
        }
       ],
       "layout": {
        "title": "Osservazione dei tumori",
        "xaxis": {
         "title": "radius_mean"
        },
        "yaxis": {
         "title": "texture_mean"
        }
       }
      },
      "text/html": [
       "<div id=\"2c164984-67f9-441f-be54-5668663ff330\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2c164984-67f9-441f-be54-5668663ff330\", [{\"marker\": {\"color\": \"rgba(0, 0, 255, .8)\", \"size\": 10}, \"mode\": \"markers\", \"name\": \"tumore beigno\", \"x\": [13.74, 13.37, 14.69, 12.91, 13.62, 15.0, 11.8, 14.53, 13.71, 11.36, 8.726, 14.47, 13.54, 12.85, 12.47, 12.46, 10.86, 11.37, 13.49, 9.567, 11.06, 14.61, 7.691, 13.69, 11.46, 12.06, 13.15, 10.26, 9.333, 11.06, 10.66, 10.51, 12.67, 11.08, 11.04, 12.43, 14.87, 12.87, 9.465, 13.16, 10.91, 12.25, 12.75, 14.58, 12.27, 12.16, 12.99, 13.27, 13.87, 13.87, 13.59, 8.95, 13.65, 11.47, 14.42, 12.05, 9.683, 10.97, 12.54, 14.34, 11.76, 13.03, 16.84, 13.21, 8.671, 11.87, 12.76, 12.65, 11.31, 11.94, 14.96, 11.6, 9.731, 11.27, 14.02, 10.51, 9.876, 11.57, 12.31, 13.66, 10.32, 12.21, 12.21, 12.87, 12.18, 16.5, 12.04, 10.05, 11.28, 8.618, 12.63, 12.54, 13.0, 10.6, 11.62, 11.89, 9.0, 9.042, 13.9, 14.95, 13.46, 14.5, 12.18, 12.9, 9.787, 12.2, 11.85, 11.41, 13.2, 16.17, 12.45, 11.95, 13.85, 15.19, 11.06, 11.14, 12.94, 13.24, 13.05, 13.85, 13.3, 12.72, 12.0, 14.26, 12.81, 9.405, 10.94, 8.597, 8.219, 10.57, 13.2, 12.39, 11.71, 14.04, 11.22, 11.93, 11.41, 12.72, 10.57, 13.27, 9.397, 14.76, 11.51, 12.58, 9.847, 9.676, 12.36, 11.63, 15.71, 14.8, 14.97, 11.3, 14.92, 10.9, 12.32, 11.43, 11.68, 11.16, 14.53, 13.56, 11.34, 13.64, 13.64, 14.59, 9.668, 13.01, 8.571, 9.876, 8.878, 12.8, 12.22, 10.96, 10.44, 12.88, 9.436, 11.6, 12.95, 8.598, 16.14, 13.59, 12.03, 12.23, 11.49, 13.66, 11.26, 12.7, 8.734, 15.1, 12.77, 14.11, 11.71, 11.71, 12.46, 11.89, 12.27, 13.85, 11.94, 11.26, 13.77, 11.69, 11.5, 14.05, 13.38, 10.49, 11.66, 10.71, 13.7, 11.99, 10.2, 11.93, 14.2, 13.05, 12.07, 11.45, 16.3, 10.8, 12.62, 10.26, 12.42, 12.49, 13.88, 9.742, 10.8, 15.73, 12.88, 9.268, 13.75, 12.3, 12.83, 11.74, 13.05, 10.88, 9.504, 11.54, 9.755, 11.75, 11.33, 12.77, 14.99, 17.85, 13.5, 12.19, 13.0, 13.14, 13.08, 8.888, 11.64, 14.29, 12.18], \"y\": [17.91, 16.39, 13.98, 16.33, 23.23, 15.51, 17.26, 13.98, 18.68, 17.57, 15.83, 24.99, 14.36, 21.37, 17.31, 19.89, 21.48, 18.89, 22.3, 15.91, 14.83, 15.69, 25.44, 16.07, 18.16, 18.9, 15.34, 16.58, 21.94, 17.12, 15.15, 20.19, 17.3, 14.71, 14.93, 17.0, 20.21, 16.21, 21.01, 20.54, 12.35, 22.44, 16.7, 13.66, 29.97, 18.03, 14.23, 14.76, 20.7, 16.21, 17.84, 15.76, 13.16, 16.03, 16.54, 14.63, 19.34, 17.2, 16.32, 13.47, 21.6, 18.42, 19.46, 28.06, 14.45, 21.54, 13.37, 18.17, 19.04, 20.76, 19.1, 18.36, 15.34, 15.5, 15.66, 23.09, 19.4, 19.04, 16.52, 19.13, 16.35, 14.09, 18.02, 19.54, 14.08, 18.29, 28.14, 17.53, 13.39, 11.79, 20.76, 18.07, 20.78, 18.95, 18.18, 21.17, 14.4, 18.9, 19.24, 18.77, 28.21, 10.89, 17.84, 15.92, 19.94, 15.21, 17.46, 14.92, 17.43, 16.07, 16.41, 14.96, 17.21, 13.21, 14.96, 14.07, 16.17, 20.13, 18.59, 19.6, 21.57, 13.78, 28.23, 19.65, 13.06, 21.7, 18.59, 18.6, 20.7, 18.32, 15.82, 17.48, 16.67, 15.98, 33.81, 21.53, 10.82, 17.67, 20.22, 17.02, 21.68, 14.74, 23.93, 18.4, 15.68, 13.14, 18.54, 29.29, 13.93, 17.66, 16.95, 18.19, 14.93, 12.96, 12.39, 17.31, 16.17, 21.41, 19.34, 13.9, 18.61, 16.34, 15.6, 22.68, 18.1, 22.22, 13.1, 17.27, 15.49, 17.46, 20.04, 17.62, 15.46, 18.22, 18.32, 12.84, 16.02, 20.98, 14.86, 21.84, 17.93, 19.56, 14.59, 15.15, 19.96, 12.17, 16.84, 16.39, 29.43, 12.88, 15.45, 17.19, 12.83, 18.35, 17.92, 15.18, 18.24, 19.83, 13.27, 24.44, 18.45, 27.15, 30.72, 18.61, 17.07, 20.39, 17.64, 24.89, 17.48, 10.91, 20.53, 13.84, 13.44, 20.97, 15.7, 21.98, 17.15, 14.71, 15.04, 16.85, 16.16, 15.67, 9.71, 11.28, 28.92, 12.87, 23.77, 15.9, 15.73, 14.69, 19.31, 15.62, 12.44, 10.72, 28.2, 20.18, 14.16, 21.41, 22.11, 13.23, 12.71, 13.29, 25.13, 20.74, 15.71, 14.64, 18.33, 16.82, 20.52], \"type\": \"scatter\", \"uid\": \"b4f9eb38-f564-11e8-bf90-309c2316f643\"}, {\"marker\": {\"color\": \"rgba(255, 0, 0, .8)\", \"size\": 10}, \"mode\": \"markers\", \"name\": \"tumore maligno\", \"x\": [17.35, 16.11, 18.49, 13.71, 15.46, 19.21, 18.81, 17.14, 19.07, 19.16, 19.8, 13.61, 11.84, 14.71, 16.65, 16.13, 21.75, 14.27, 15.06, 27.22, 21.16, 20.16, 12.45, 18.65, 15.61, 14.68, 11.42, 17.06, 14.58, 12.83, 20.48, 14.86, 17.47, 12.34, 20.09, 17.95, 16.69, 16.35, 14.25, 17.3, 20.59, 16.27, 17.29, 18.03, 11.76, 14.99, 19.18, 11.8, 25.73, 24.63, 17.46, 19.44, 20.47, 20.18, 24.25, 23.29, 20.34, 20.44, 18.82, 21.71, 15.75, 18.22, 19.53, 19.79, 15.05, 19.59, 20.64, 17.08, 20.51, 23.27, 18.22, 18.08, 15.66, 18.01, 19.0, 17.91, 13.17, 14.78, 16.24, 18.46, 18.31, 19.17, 16.74, 15.3, 20.26, 15.75, 16.25, 10.95, 15.46, 15.49, 19.4, 19.45, 20.29, 19.55, 14.9, 13.61, 17.42, 13.43, 13.86, 13.17, 17.02, 15.5, 18.45, 18.61, 17.05, 20.31, 19.59, 18.31, 14.95, 14.25, 12.77, 13.0, 12.68, 19.53, 13.73, 17.68, 13.44, 11.08, 18.77, 23.21, 17.01, 28.11, 27.42, 16.6, 17.54, 19.19, 13.28, 14.22, 15.53, 13.11, 19.55, 20.57, 15.12, 16.13, 20.2, 15.37, 23.51, 15.85, 20.92, 19.73, 14.6, 19.68, 14.42, 21.37, 19.02, 16.03, 14.19, 18.66, 13.98], \"y\": [23.06, 18.05, 17.52, 20.83, 11.89, 18.57, 19.98, 16.4, 24.81, 26.6, 21.56, 24.69, 18.7, 21.59, 21.38, 20.68, 20.99, 22.55, 19.83, 21.87, 23.04, 19.66, 15.7, 17.6, 19.38, 20.13, 20.38, 21.0, 21.53, 22.33, 21.46, 23.21, 24.68, 26.86, 23.86, 20.01, 20.2, 23.29, 21.72, 17.08, 21.24, 20.71, 22.13, 16.85, 18.14, 25.2, 22.49, 16.58, 17.46, 21.6, 39.28, 18.82, 20.67, 19.54, 20.2, 26.67, 21.51, 21.78, 21.97, 17.25, 20.25, 18.7, 32.47, 25.12, 19.07, 25.0, 17.35, 27.15, 27.81, 22.04, 18.87, 21.84, 23.2, 20.56, 18.91, 21.02, 21.81, 23.94, 18.77, 18.52, 18.58, 24.8, 21.59, 25.27, 23.03, 19.22, 19.51, 21.35, 23.95, 19.97, 18.18, 19.33, 14.34, 28.77, 22.53, 24.98, 25.56, 19.63, 16.93, 18.66, 23.98, 21.08, 21.91, 20.25, 19.08, 27.06, 18.15, 20.58, 17.57, 22.15, 22.47, 21.82, 23.84, 18.9, 22.61, 20.74, 21.58, 18.83, 21.43, 26.97, 20.26, 18.47, 26.27, 28.08, 19.32, 15.94, 20.28, 23.12, 33.56, 15.56, 23.21, 17.77, 16.68, 17.88, 26.83, 22.76, 24.27, 23.95, 25.09, 19.82, 23.29, 21.68, 19.77, 15.1, 24.59, 15.51, 23.81, 17.12, 19.62], \"type\": \"scatter\", \"uid\": \"b4f9fe9e-f564-11e8-83a9-309c2316f643\"}], {\"title\": \"Osservazione dei tumori\", \"xaxis\": {\"title\": \"radius_mean\"}, \"yaxis\": {\"title\": \"texture_mean\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2c164984-67f9-441f-be54-5668663ff330\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2c164984-67f9-441f-be54-5668663ff330\", [{\"marker\": {\"color\": \"rgba(0, 0, 255, .8)\", \"size\": 10}, \"mode\": \"markers\", \"name\": \"tumore beigno\", \"x\": [13.74, 13.37, 14.69, 12.91, 13.62, 15.0, 11.8, 14.53, 13.71, 11.36, 8.726, 14.47, 13.54, 12.85, 12.47, 12.46, 10.86, 11.37, 13.49, 9.567, 11.06, 14.61, 7.691, 13.69, 11.46, 12.06, 13.15, 10.26, 9.333, 11.06, 10.66, 10.51, 12.67, 11.08, 11.04, 12.43, 14.87, 12.87, 9.465, 13.16, 10.91, 12.25, 12.75, 14.58, 12.27, 12.16, 12.99, 13.27, 13.87, 13.87, 13.59, 8.95, 13.65, 11.47, 14.42, 12.05, 9.683, 10.97, 12.54, 14.34, 11.76, 13.03, 16.84, 13.21, 8.671, 11.87, 12.76, 12.65, 11.31, 11.94, 14.96, 11.6, 9.731, 11.27, 14.02, 10.51, 9.876, 11.57, 12.31, 13.66, 10.32, 12.21, 12.21, 12.87, 12.18, 16.5, 12.04, 10.05, 11.28, 8.618, 12.63, 12.54, 13.0, 10.6, 11.62, 11.89, 9.0, 9.042, 13.9, 14.95, 13.46, 14.5, 12.18, 12.9, 9.787, 12.2, 11.85, 11.41, 13.2, 16.17, 12.45, 11.95, 13.85, 15.19, 11.06, 11.14, 12.94, 13.24, 13.05, 13.85, 13.3, 12.72, 12.0, 14.26, 12.81, 9.405, 10.94, 8.597, 8.219, 10.57, 13.2, 12.39, 11.71, 14.04, 11.22, 11.93, 11.41, 12.72, 10.57, 13.27, 9.397, 14.76, 11.51, 12.58, 9.847, 9.676, 12.36, 11.63, 15.71, 14.8, 14.97, 11.3, 14.92, 10.9, 12.32, 11.43, 11.68, 11.16, 14.53, 13.56, 11.34, 13.64, 13.64, 14.59, 9.668, 13.01, 8.571, 9.876, 8.878, 12.8, 12.22, 10.96, 10.44, 12.88, 9.436, 11.6, 12.95, 8.598, 16.14, 13.59, 12.03, 12.23, 11.49, 13.66, 11.26, 12.7, 8.734, 15.1, 12.77, 14.11, 11.71, 11.71, 12.46, 11.89, 12.27, 13.85, 11.94, 11.26, 13.77, 11.69, 11.5, 14.05, 13.38, 10.49, 11.66, 10.71, 13.7, 11.99, 10.2, 11.93, 14.2, 13.05, 12.07, 11.45, 16.3, 10.8, 12.62, 10.26, 12.42, 12.49, 13.88, 9.742, 10.8, 15.73, 12.88, 9.268, 13.75, 12.3, 12.83, 11.74, 13.05, 10.88, 9.504, 11.54, 9.755, 11.75, 11.33, 12.77, 14.99, 17.85, 13.5, 12.19, 13.0, 13.14, 13.08, 8.888, 11.64, 14.29, 12.18], \"y\": [17.91, 16.39, 13.98, 16.33, 23.23, 15.51, 17.26, 13.98, 18.68, 17.57, 15.83, 24.99, 14.36, 21.37, 17.31, 19.89, 21.48, 18.89, 22.3, 15.91, 14.83, 15.69, 25.44, 16.07, 18.16, 18.9, 15.34, 16.58, 21.94, 17.12, 15.15, 20.19, 17.3, 14.71, 14.93, 17.0, 20.21, 16.21, 21.01, 20.54, 12.35, 22.44, 16.7, 13.66, 29.97, 18.03, 14.23, 14.76, 20.7, 16.21, 17.84, 15.76, 13.16, 16.03, 16.54, 14.63, 19.34, 17.2, 16.32, 13.47, 21.6, 18.42, 19.46, 28.06, 14.45, 21.54, 13.37, 18.17, 19.04, 20.76, 19.1, 18.36, 15.34, 15.5, 15.66, 23.09, 19.4, 19.04, 16.52, 19.13, 16.35, 14.09, 18.02, 19.54, 14.08, 18.29, 28.14, 17.53, 13.39, 11.79, 20.76, 18.07, 20.78, 18.95, 18.18, 21.17, 14.4, 18.9, 19.24, 18.77, 28.21, 10.89, 17.84, 15.92, 19.94, 15.21, 17.46, 14.92, 17.43, 16.07, 16.41, 14.96, 17.21, 13.21, 14.96, 14.07, 16.17, 20.13, 18.59, 19.6, 21.57, 13.78, 28.23, 19.65, 13.06, 21.7, 18.59, 18.6, 20.7, 18.32, 15.82, 17.48, 16.67, 15.98, 33.81, 21.53, 10.82, 17.67, 20.22, 17.02, 21.68, 14.74, 23.93, 18.4, 15.68, 13.14, 18.54, 29.29, 13.93, 17.66, 16.95, 18.19, 14.93, 12.96, 12.39, 17.31, 16.17, 21.41, 19.34, 13.9, 18.61, 16.34, 15.6, 22.68, 18.1, 22.22, 13.1, 17.27, 15.49, 17.46, 20.04, 17.62, 15.46, 18.22, 18.32, 12.84, 16.02, 20.98, 14.86, 21.84, 17.93, 19.56, 14.59, 15.15, 19.96, 12.17, 16.84, 16.39, 29.43, 12.88, 15.45, 17.19, 12.83, 18.35, 17.92, 15.18, 18.24, 19.83, 13.27, 24.44, 18.45, 27.15, 30.72, 18.61, 17.07, 20.39, 17.64, 24.89, 17.48, 10.91, 20.53, 13.84, 13.44, 20.97, 15.7, 21.98, 17.15, 14.71, 15.04, 16.85, 16.16, 15.67, 9.71, 11.28, 28.92, 12.87, 23.77, 15.9, 15.73, 14.69, 19.31, 15.62, 12.44, 10.72, 28.2, 20.18, 14.16, 21.41, 22.11, 13.23, 12.71, 13.29, 25.13, 20.74, 15.71, 14.64, 18.33, 16.82, 20.52], \"type\": \"scatter\", \"uid\": \"b4f9eb38-f564-11e8-bf90-309c2316f643\"}, {\"marker\": {\"color\": \"rgba(255, 0, 0, .8)\", \"size\": 10}, \"mode\": \"markers\", \"name\": \"tumore maligno\", \"x\": [17.35, 16.11, 18.49, 13.71, 15.46, 19.21, 18.81, 17.14, 19.07, 19.16, 19.8, 13.61, 11.84, 14.71, 16.65, 16.13, 21.75, 14.27, 15.06, 27.22, 21.16, 20.16, 12.45, 18.65, 15.61, 14.68, 11.42, 17.06, 14.58, 12.83, 20.48, 14.86, 17.47, 12.34, 20.09, 17.95, 16.69, 16.35, 14.25, 17.3, 20.59, 16.27, 17.29, 18.03, 11.76, 14.99, 19.18, 11.8, 25.73, 24.63, 17.46, 19.44, 20.47, 20.18, 24.25, 23.29, 20.34, 20.44, 18.82, 21.71, 15.75, 18.22, 19.53, 19.79, 15.05, 19.59, 20.64, 17.08, 20.51, 23.27, 18.22, 18.08, 15.66, 18.01, 19.0, 17.91, 13.17, 14.78, 16.24, 18.46, 18.31, 19.17, 16.74, 15.3, 20.26, 15.75, 16.25, 10.95, 15.46, 15.49, 19.4, 19.45, 20.29, 19.55, 14.9, 13.61, 17.42, 13.43, 13.86, 13.17, 17.02, 15.5, 18.45, 18.61, 17.05, 20.31, 19.59, 18.31, 14.95, 14.25, 12.77, 13.0, 12.68, 19.53, 13.73, 17.68, 13.44, 11.08, 18.77, 23.21, 17.01, 28.11, 27.42, 16.6, 17.54, 19.19, 13.28, 14.22, 15.53, 13.11, 19.55, 20.57, 15.12, 16.13, 20.2, 15.37, 23.51, 15.85, 20.92, 19.73, 14.6, 19.68, 14.42, 21.37, 19.02, 16.03, 14.19, 18.66, 13.98], \"y\": [23.06, 18.05, 17.52, 20.83, 11.89, 18.57, 19.98, 16.4, 24.81, 26.6, 21.56, 24.69, 18.7, 21.59, 21.38, 20.68, 20.99, 22.55, 19.83, 21.87, 23.04, 19.66, 15.7, 17.6, 19.38, 20.13, 20.38, 21.0, 21.53, 22.33, 21.46, 23.21, 24.68, 26.86, 23.86, 20.01, 20.2, 23.29, 21.72, 17.08, 21.24, 20.71, 22.13, 16.85, 18.14, 25.2, 22.49, 16.58, 17.46, 21.6, 39.28, 18.82, 20.67, 19.54, 20.2, 26.67, 21.51, 21.78, 21.97, 17.25, 20.25, 18.7, 32.47, 25.12, 19.07, 25.0, 17.35, 27.15, 27.81, 22.04, 18.87, 21.84, 23.2, 20.56, 18.91, 21.02, 21.81, 23.94, 18.77, 18.52, 18.58, 24.8, 21.59, 25.27, 23.03, 19.22, 19.51, 21.35, 23.95, 19.97, 18.18, 19.33, 14.34, 28.77, 22.53, 24.98, 25.56, 19.63, 16.93, 18.66, 23.98, 21.08, 21.91, 20.25, 19.08, 27.06, 18.15, 20.58, 17.57, 22.15, 22.47, 21.82, 23.84, 18.9, 22.61, 20.74, 21.58, 18.83, 21.43, 26.97, 20.26, 18.47, 26.27, 28.08, 19.32, 15.94, 20.28, 23.12, 33.56, 15.56, 23.21, 17.77, 16.68, 17.88, 26.83, 22.76, 24.27, 23.95, 25.09, 19.82, 23.29, 21.68, 19.77, 15.1, 24.59, 15.51, 23.81, 17.12, 19.62], \"type\": \"scatter\", \"uid\": \"b4f9fe9e-f564-11e8-83a9-309c2316f643\"}], {\"title\": \"Osservazione dei tumori\", \"xaxis\": {\"title\": \"radius_mean\"}, \"yaxis\": {\"title\": \"texture_mean\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution (to be completed)\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected = True)\n",
    "\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = xTrain[yTrain==1,0],\n",
    "    y = xTrain[yTrain==1,1],\n",
    "    name=\"tumore maligno\",\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 10,\n",
    "        color = 'rgba(255, 0, 0, .8)',\n",
    "\n",
    "    )\n",
    ")\n",
    "trace0 = go.Scatter(\n",
    "    x = xTrain[yTrain== -1,0],\n",
    "    y = xTrain[yTrain==-1,1],\n",
    "    name=\"tumore beigno\",\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 10,\n",
    "        color = 'rgba(0, 0, 255, .8)',\n",
    "\n",
    "    )\n",
    ")\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout( title = 'Osservazione dei tumori',\n",
    "                    xaxis = {'title': 'radius_mean'},\n",
    "                    yaxis = {'title': 'texture_mean'})\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "In tutti e quattro i casi la classe sarebbe sempre tumore benigno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3\n",
    "### 1.3.1 \n",
    "Scrivere una funzione ``y_hat = knn(xTrainScaled,yTrain,xTestScaled,k,th)`` che implementa l'algoritmo di classificazione k-NN. \n",
    "\n",
    "La funzione riceve come parametri di ingress0:\n",
    "- ``xTrainScaled``: array di 2 dimensioni contente gli attributi (già normalizzati) delle osservazioni del training set. Numero di righe: m (numero di osservazioni), numero di colonne: n (numero degli attributi considerati).\n",
    "- ``yTrain``: array di 1 dimensione contente le m osservazioni della variabile target del training set\n",
    "- ``xTestScaled``: array di 2 dimensioni contente gli attributi (già normalizzati) delle osservazioni del test set di cui si vuole stimare la classe. Numero di righe: t (numero di osservazioni del test set), numero di colonne: n (numero degli attributi considerati).\n",
    "- ``k``: numero intero dispari. Parametro dell'algoritmo k-NN. \n",
    "- ``th``: soglia (o threshould in inglese). Numero intero positivo compreso tra 0 e 1. E' il valore soglia dell'algoritmo. La variabile di test è attributa alla classe positiva se lo ``score`` della classe positiva è maggiore o uguale a ``th``. Data un'istanza di test, lo score della classe positiva  è uguale a $p/k$, dove $p$ è il numero di istanze positive tra le k istanze piu' vicine. Esempio per k=9. Data un'istanza di test, se tra le 9 istanze di training piu' vicine ci sono 5 istanze positive, allora p=5 e lo score è uguale a = 5/9.   Se usate un criterio di maggioranza (come visto a lezione), allora ``th = 0.5``.\n",
    "\n",
    "La funzione restituisce:\n",
    "- ``y_hat``: array di 1 dimensione contente la stima della classe delle t osservazioni del test set\n",
    "- ``y_score``: array di 1 dimensione contente la score (della classe positiva) per ogni osservazione del test set. \n",
    "\n",
    "Valutate il comportamento della funzione appena creata sui dati di test per k=9 e th = 0.5. Usate sempre i primi 2 attributi (radius_mean e texture_mean). Quale è l'accuratezza del vostro classificatore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n",
      "Accuratezza: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning:\n",
      "\n",
      "elementwise == comparison failed; this will raise an error in the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution 1.3.1 (to be completed)\n",
    "\n",
    "def knn(xTrainScaled, yTrain, xTestScaled, k, th):\n",
    "    \n",
    "    # Valuta dimensione del set di training\n",
    "    if np.ndim(xTrainScaled)>1:\n",
    "        (m,n) = np.shape(xTrainScaled)\n",
    "    else:\n",
    "        n = 1\n",
    "        m = np.shape(xTrainScaled)[0]\n",
    "        np.reshape(xTrainScaled,(m,1)) # Fai un reshape per avere array di dimension 2\n",
    "        \n",
    "    t = np.shape(xTestScaled)[0] # Dimensione del set di training\n",
    "\n",
    "    y_hat = np.zeros(t)\n",
    "    y_score = np.zeros(t) \n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return y_hat, y_score\n",
    "\n",
    "\n",
    "y_hat, y_score = knn(xTrainScaled[:,0:2], yTrain, xTestScaled[:,0:2], k=9, th=0.5)\n",
    "accuracy = np.mean(yTrain == y_hat)\n",
    "print(f\"Accuratezza: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2  \n",
    "Scrivere una funzione ``accuracy, TP, FP, FN, TN, TPR, FPR = evaluatekNN(yTest,y_hat)`` che, dato l'array con la classe vera ``yTest``delle osservazioni di test e la classe stimata ``y_hat`` dall'algoritmo kNN, restituisce:\n",
    "- accuary: accuratezza dell'algoritmo\n",
    "- TP, FP, FN, TN, TPR, FPR: True Positive, Falso Positive, False Negative, True Negative, True Positive Rate, False Positive Rate.\n",
    "\n",
    "Valutate il comportamento della funzione appena creata usando la predizione della classe y_hat calcolata al passo precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0; TPR = 0.0; FPR = 1.0; ....... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution 1.3.2 (to be completed)\n",
    "\n",
    "def evaluatekNN(yTest,y_hat):\n",
    "\n",
    "    TP=0\n",
    "    FP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    for i in range (len(yTest)):            \n",
    "        if (yTest[i]==y_hat[i]):\n",
    "            if(yTest[i]>0):\n",
    "                TP+=1\n",
    "            else:\n",
    "                TN+=1\n",
    "        else:\n",
    "            if(yTest[i]<0):\n",
    "                FP+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "\n",
    "    TPR=TP/(TP+FN)\n",
    "    FPR=FP/(FP+TN)\n",
    "    accuracy=(TP+TN)/len(yTest)\n",
    "    \n",
    "    return accuracy, TP, FP, FN, TN, TPR, FPR\n",
    "\n",
    "accuracy, TP, FP, FN, TN, TPR, FPR = evaluatekNN(yTest,y_hat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}; TPR = {TPR}; FPR = {FPR}; ....... \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 \n",
    "\n",
    "- In un'applicazione diagnostica come quella che stiamo considerando in questo esercizio, è meglio avere un TPR alto (a discapito di un FPR alto) o un TPR basso (col vantaggio di avere un FPR basso)?\n",
    "\n",
    "- Come posso fare ad aumentare (o diminuire) il TPR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "A dipendenza della soluzione da intraprendere e dai suoi costi è meglio uno o l'altro. Se abbiamo i costi alti è meglio un TPR basso altrimenti se i costi sono bassi allora un TPR alto fa al caso nostro.\n",
    "\n",
    "Per aumentare o diminuire i TPR basta semplicemente cambiare la nostra k e la nostra soglia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4\n",
    "Disegnate la curva ROC (variando il parametro di soglia `th`) per $k=5$, $k=9$ e $k=m$ (dove m è la lunghezza del set di training). Si consideri sempre i primi 2 attributi. \n",
    "\n",
    "- Cosa succede se ``th=0``? E se ``th=1``?\n",
    "\n",
    "- Calcolare la AUC (area under curve) delle 3 ROC disegnate sopra: comando per calcolare la AUC:  ``roc_auc_score(yTest,y_score)``\n",
    "\n",
    "- (opzionale) Sapete spiegare perchè per $k=m$ il classificatore si comporta sempre come il baseline (dummy) classifier?\n",
    "\n",
    "- Quale dei 3 classificatori scegliete? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.3.4 (to be completed)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kvec = [5,9,m]\n",
    "data = [] # Qui metterò i dati per disegnare la ROC. Ogni elemento della lista sarà un oggetto di classe go.Scatter  \n",
    "AUC = [] # Area under curve. Sarà una lista con 3 elementi (un elemento per ogni valore di \"k\")\n",
    "\n",
    "for k in kvec: \n",
    "    \n",
    "    thvec = np.linspace(0,1,k+1) #Valori di soglia considerati\n",
    "    TPRlist = [] # In questa lista inseriro' il TPR per ogni valore di soglia. Nota che la lista viene inizializzata ogni volta che cambio \"k\"\n",
    "    FPRlist = [] # In questa lista inseriro' il FPR per ogni valore di soglia.\n",
    "    \n",
    "    \n",
    "    for th in thvec:\n",
    "\n",
    "        y_hat,y_score = ...\n",
    "        \n",
    "        ...\n",
    "    \n",
    "    \n",
    "    AUC.append(roc_auc_score(yTest,y_score))\n",
    "    data.append(go.Scatter(x = FPRlist, y = TPRlist, text = tvec, mode = 'markers+lines', name = f'k-NN classifier for k={k}'))\n",
    "    print(f\"k = {k}: AUC: {AUC[-1]}\")\n",
    "\n",
    "\n",
    "data.append(go.Scatter(x = [0, 1], y = [0, 1], mode = 'lines', name = 'baseline classifier', line = dict(dash = 'dash')))\n",
    "layout = go.Layout(xaxis = dict(title = 'FPR'), yaxis = dict(title = 'TPR'), title = 'Curva ROC del classificatore k-NN sul dataset Breast Cancer')\n",
    "\n",
    "fig = go.Figure(data, layout)\n",
    "py.iplot(fig)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 (simile all'esercizio fatto nell'esercitazione scorsa)\n",
    "Si calcoli l'indice di accuratezza (sul test set) dell'algoritmo di classificazione k-NN (per k=9 e th=0.5) considerando un numero crescente dei possibili attributi. Nello specifico, dati i possibili attributi ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'area_worst', 'smoothness_worst'], si calcoli l'indice di accuratezza per i seguenti casi:\n",
    "- attributi considerati: ['radius_mean', 'texture_mean']\n",
    "- attributi considerati: ['radius_mean', 'texture_mean', 'perimeter_mean']\n",
    "- attributi considerati: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean']\n",
    "- ...\n",
    "- attributi considerati: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'area_worst', 'smoothness_worst']\n",
    "\n",
    "La cella sotto carica tutti i 9 attributi di sopra negli array ``xTrain2`` e ``xTest2``  \n",
    "\n",
    "E' vero che all'aumentare del numero di attributi l'indice di accuratezza aumenta sempre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di attributi considerati = 2\n",
      "\n",
      "171\n",
      "Numero di attributi considerati = 3\n",
      "\n",
      "171\n",
      "Numero di attributi considerati = 4\n",
      "\n",
      "171\n",
      "Numero di attributi considerati = 5\n",
      "\n",
      "171\n",
      "Numero di attributi considerati = 6\n",
      "\n",
      "171\n",
      "Numero di attributi considerati = 7\n",
      "\n",
      "171\n",
      "Numero di attributi considerati = 8\n",
      "\n",
      "171\n",
      "Numero di attributi considerati = 9\n",
      "\n",
      "171\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Solution (to be completed)\n",
    "\n",
    "index = [0,1,3,4,5,6,7,23,24] # indici degli attributi considerati nei dataset xTrain e xTest\n",
    "xTrain2 = xTrainScaled[:,index]\n",
    "xTest2 = xTestScaled[:,index]\n",
    "\n",
    "k = 9\n",
    "th = 0.5\n",
    "\n",
    "accuracyList = []\n",
    "\n",
    "\n",
    "for n in range(2,10):\n",
    "    print(f\"Numero di attributi considerati = {n}\\n\")\n",
    "    y_hat,y_score = knn(xTrain2[:,0:n], yTrain, xTest2[:,0:n], k, th)\n",
    "    accuracy, TP, FP, FN, TN, TPR, FPR = evaluatekNN(yTest,y_hat)\n",
    "    accuracyList.append(accuracy)\n",
    "\n",
    "print(accuracyList) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 (opzionale, ma vi consigliamo di provare a farlo per capire bene come funziona la cross-validation): Scelta delle features tramite K-fold cross-validation\n",
    "\n",
    "Si implementi un metodo di cross-validation per scegliere la migliore combinazione delle features tra 10 possibili combinazioni. \n",
    "\n",
    "Si consideri sempre un k-nearest-neighbor con $k=5$ e $th=0.5$.\n",
    "\n",
    "Per implementare il metodo di cross-validation, dovete ripartire il dataset di training in $K$ sottoinsiemi disgiunti (ed esaustivi). Usiamo $K=4$.\n",
    "\n",
    "La cella sotto vi mostra un possibile modo di implementare la cross-validation, usando una classe disponibile in sklearn.  Nota: Potete anche fare voi la divisione manualmente, senza usare i comandi di sklearn riportati nella cella sotto. \n",
    "\n",
    "Nota: Ripasso sulla K-fold cross-validation, per K=4. Dopo aver suddiviso il dataset in 4 sottoinsiemi, usate 3 insiemi per fare il training, e il restante per misurare l'accuratezza. Ripete l'operazione 4 volte cambiando ogni volta il set di test e calcolate l'accuratezza come media aritmetica delle accuratezze. Dovete ripete questa operazione per tutte le possibile combinazioni degli attributi e scegliere la combinazione con l'accuratezza media massima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio: divisione di un dataset in K=3 fold\n",
    "\n",
    "# Creo un semplice dataset\n",
    "x_toy = np.random.rand(10,2) # 10 osservazioni e 2 features\n",
    "y_toy = np.array([1, 1, 1, 1, 1, -1, -1, -1, -1, -1])\n",
    "\n",
    "print(\"Dataset completo\\n\", x_toy)\n",
    "print()\n",
    "\n",
    "import sklearn.model_selection\n",
    "K = 3\n",
    "kf = sklearn.model_selection.KFold(n_splits=K, shuffle=True)\n",
    "splits = list(kf.split(x_toy))\n",
    "print(f\"Splits e' una lista di K={len(splits)} tuple\\n\")\n",
    "\n",
    "# ogni tupla e' composta da due elementi:\n",
    "# - il primo e' una lista di indici da usare per il training\n",
    "# - il secondo e' una lista di indici da usare per il testing\n",
    "for train_index, test_index in splits:\n",
    "    print(\"Split:\")\n",
    "    print(\"Indici di training: \", train_index)\n",
    "    print(\"Indici di testing: \", test_index)\n",
    "    x_toy_train = x_toy[train_index, :]\n",
    "    y_toy_train = y_toy[train_index]\n",
    "    x_toy_test  = x_toy[test_index , :]\n",
    "    y_toy_test  = y_toy[test_index]\n",
    "    print(\"Dati di training:\\n\", x_toy_train)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Implementazione della cross validation\n",
    "\n",
    "Per una determinata scelta delle feature (ad esempio, quelle agli indici `[0,1,3,4,5,6,7,23,24]`), calcola l'accuratezza del classificatore mediante 4-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.5.1 (to be completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Comparazione tra diversi sottoinsiemi di feature\n",
    "\n",
    "Scopri quali tra le combinazioni di feature proposte sotto e' preferibile, calcolando per ciascuna delle 6 combinazioni l'accuratezza tramite K-fold cross validation.\n",
    "\n",
    "Esempio di output:\n",
    "```\n",
    "Considero le features: [0]\n",
    "Accuracy per un fold: 0.8181818181818182\n",
    "Accuracy per un fold: 0.8661971830985915\n",
    "Accuracy per un fold: 0.9225352112676056\n",
    "Accuracy per un fold: 0.8591549295774648\n",
    "Accuracy media: 0.8665172855313701\n",
    "\n",
    "Considero le features: [0, 1]\n",
    "Accuracy per un fold: 0.8531468531468531\n",
    "Accuracy per un fold: 0.8591549295774648\n",
    "Accuracy per un fold: 0.9154929577464789\n",
    "Accuracy per un fold: 0.8802816901408451\n",
    "Accuracy media: 0.8770191076529105\n",
    "\n",
    "Considero le features: [0, 1, 3]\n",
    "Accuracy per un fold: 0.8671328671328671\n",
    "Accuracy per un fold: 0.8591549295774648\n",
    "Accuracy per un fold: 0.9084507042253521\n",
    "Accuracy per un fold: 0.8802816901408451\n",
    "Accuracy media: 0.8787550477691323\n",
    "\n",
    "Considero le features: [0, 1, 3, 4, 5, 6, 7, 23, 24]\n",
    "Accuracy per un fold: 0.9300699300699301\n",
    "Accuracy per un fold: 0.971830985915493\n",
    "Accuracy per un fold: 0.971830985915493\n",
    "Accuracy per un fold: 0.9507042253521126\n",
    "Accuracy media: 0.9561090318132571\n",
    "\n",
    "Considero le features: [3, 4]\n",
    "Accuracy per un fold: 0.8671328671328671\n",
    "Accuracy per un fold: 0.8873239436619719\n",
    "Accuracy per un fold: 0.9084507042253521\n",
    "Accuracy per un fold: 0.8732394366197183\n",
    "Accuracy media: 0.8840367379099774\n",
    "\n",
    "Considero le features: [7, 23, 24]\n",
    "Accuracy per un fold: 0.9230769230769231\n",
    "Accuracy per un fold: 0.971830985915493\n",
    "Accuracy per un fold: 0.9436619718309859\n",
    "Accuracy per un fold: 0.9366197183098591\n",
    "Accuracy media: 0.9437973997833152\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.5.2 (to be completed)\n",
    "\n",
    "featurecombinations = [[0                  ],\n",
    "                       [0,1                ],\n",
    "                       [0,1,3              ],\n",
    "                       [0,1,3,4,5,6,7,23,24],\n",
    "                       [    3,4            ],\n",
    "                       [            7,23,24]]\n",
    "\n",
    "K = 4 # numero di fold\n",
    "kf = sklearn.model_selection.KFold(n_splits=K, shuffle=True)\n",
    "splits = list(kf.split(x))\n",
    "\n",
    "\n",
    "k = 5 # per il knn\n",
    "th = 0.5\n",
    "\n",
    "accuracyPerFeature = [] # Ogni elemento della lista sarà l'accuratezza (media) che si ottiene per una data combinazione di features\n",
    "\n",
    "for featurecombination in featurecombinations: # Ciclo su tutte le combinazioni di features\n",
    "    x_feat = x[:, featurecombination]\n",
    "    \n",
    "    print(f\"Considero le features: {featurecombination}\")\n",
    "    \n",
    "    ### Completare..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 Comparazione tra tutti i possibili sottoinsiemi di feature\n",
    "\n",
    "Considera tutti i possibili sottoinsiemi delle feature agli indici `[0,1,3,4,5,6,7,23,24]`.  Calcola per ciascun sottoinsieme (ce ne sono in tutto $2^9 - 1$) l'accuratezza mediante 4-fold cross-validation, e trova quello che restituisce accuratezza massima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.5.3 (to be completed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
